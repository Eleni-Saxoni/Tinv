{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "814283b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "import spacy\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65ed1f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18.5\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a084a718",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('Tweettrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f315fbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28b57f3990</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>http://www.dothebouncy.com/smf - some shameles...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6e0c6d75b1</td>\n",
       "      <td>2am feedings for the baby are fun when he is a...</td>\n",
       "      <td>fun</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50e14c0bb8</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>Soooo high</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>e050245fbd</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>Both of you</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>fc2cbefa9d</td>\n",
       "      <td>Journey!? Wow... u just became cooler.  hehe....</td>\n",
       "      <td>Wow... u just became cooler.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2339a9b08b</td>\n",
       "      <td>as much as i love to be hopeful, i reckon the...</td>\n",
       "      <td>as much as i love to be hopeful, i reckon the ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16fab9f95b</td>\n",
       "      <td>I really really like the song Love Story by Ta...</td>\n",
       "      <td>like</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>74a76f6e0a</td>\n",
       "      <td>My Sharpie is running DANGERously low on ink</td>\n",
       "      <td>DANGERously</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>04dd1d2e34</td>\n",
       "      <td>i want to go to music tonight but i lost my vo...</td>\n",
       "      <td>lost</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>bbe3cbf620</td>\n",
       "      <td>test test from the LG enV2</td>\n",
       "      <td>test test from the LG enV2</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        textID                                               text  \\\n",
       "0   cb774db0d1                I`d have responded, if I were going   \n",
       "1   549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2   088c60f138                          my boss is bullying me...   \n",
       "3   9642c003ef                     what interview! leave me alone   \n",
       "4   358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "5   28b57f3990  http://www.dothebouncy.com/smf - some shameles...   \n",
       "6   6e0c6d75b1  2am feedings for the baby are fun when he is a...   \n",
       "7   50e14c0bb8                                         Soooo high   \n",
       "8   e050245fbd                                        Both of you   \n",
       "9   fc2cbefa9d   Journey!? Wow... u just became cooler.  hehe....   \n",
       "10  2339a9b08b   as much as i love to be hopeful, i reckon the...   \n",
       "11  16fab9f95b  I really really like the song Love Story by Ta...   \n",
       "12  74a76f6e0a       My Sharpie is running DANGERously low on ink   \n",
       "13  04dd1d2e34  i want to go to music tonight but i lost my vo...   \n",
       "14  bbe3cbf620                         test test from the LG enV2   \n",
       "\n",
       "                                        selected_text sentiment  \n",
       "0                 I`d have responded, if I were going   neutral  \n",
       "1                                            Sooo SAD  negative  \n",
       "2                                         bullying me  negative  \n",
       "3                                      leave me alone  negative  \n",
       "4                                       Sons of ****,  negative  \n",
       "5   http://www.dothebouncy.com/smf - some shameles...   neutral  \n",
       "6                                                 fun  positive  \n",
       "7                                          Soooo high   neutral  \n",
       "8                                         Both of you   neutral  \n",
       "9                        Wow... u just became cooler.  positive  \n",
       "10  as much as i love to be hopeful, i reckon the ...   neutral  \n",
       "11                                               like  positive  \n",
       "12                                        DANGERously  negative  \n",
       "13                                               lost  negative  \n",
       "14                         test test from the LG enV2   neutral  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2abcf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['text','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb89998e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"text\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dab8c22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"text\"].fillna(\"No content\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "092c4fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depure_data(data):\n",
    "    \n",
    "    #Removing URLs with a regular expression\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    data = url_pattern.sub(r'', data)\n",
    "\n",
    "    # Remove Emails\n",
    "    data = re.sub('\\S*@\\S*\\s?', '', data)\n",
    "\n",
    "    # Remove new line characters\n",
    "    data = re.sub('\\s+', ' ', data)\n",
    "\n",
    "    # Remove distracting single quotes\n",
    "    data = re.sub(\"\\'\", \"\", data)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bd22f942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' I`d have responded, if I were going',\n",
       " ' Sooo SAD I will miss you here in San Diego!!!',\n",
       " 'my boss is bullying me...',\n",
       " ' what interview! leave me alone',\n",
       " ' Sons of ****, why couldn`t they put them on the releases we already bought']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = []\n",
    "#Splitting pd.Series to list\n",
    "data_to_list = train['text'].values.tolist()\n",
    "for i in range(len(data_to_list)):\n",
    "    temp.append(depure_data(data_to_list[i]))\n",
    "list(temp[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e8a2eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        nopunct = re.sub(r'[^\\w\\s]','',sentence)\n",
    "        yield(nopunct.lower().split())  \n",
    "        \n",
    "\n",
    "data_words = list(sent_to_words(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf917545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detokenize(text):\n",
    "    return TreebankWordDetokenizer().detokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a9e6cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(len(data_words)):\n",
    "    data.append(detokenize(data_words[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f54ab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ce27d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(train['sentiment'])\n",
    "y = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 'neutral':\n",
    "        y.append(0)\n",
    "    if labels[i] == 'negative':\n",
    "        y.append(1)\n",
    "    if labels[i] == 'positive':\n",
    "        y.append(2)\n",
    "y = np.array(y)\n",
    "labels = tf.keras.utils.to_categorical(y, 3, dtype=\"float32\")\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60387b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...    1  119   45]\n",
      " [   0    0    0 ...   10 1462 2229]\n",
      " [   0    0    0 ... 1300    9   15]\n",
      " ...\n",
      " [   0    0    0 ...  631  874 2747]\n",
      " [   0    0    0 ...   27  686    8]\n",
      " [   0    0    0 ... 2230  224  666]]\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.optimizers import RMSprop,Adam\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "max_words = 5000\n",
    "max_len = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data)\n",
    "sequences = tokenizer.texts_to_sequences(data)\n",
    "tweets = pad_sequences(sequences, maxlen=max_len)\n",
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d7a9b0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5d8a1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20610 6871 20610 6871\n"
     ]
    }
   ],
   "source": [
    "#Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(tweets,labels, random_state=0)\n",
    "print (len(X_train),len(X_test),len(y_train),len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5cbab58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.18.5'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed4bd6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.9734 - accuracy: 0.5036\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.61054, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 34s 53ms/step - loss: 0.9734 - accuracy: 0.5036 - val_loss: 0.8373 - val_accuracy: 0.6105\n",
      "Epoch 2/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.7853 - accuracy: 0.6492\n",
      "Epoch 00002: val_accuracy improved from 0.61054 to 0.67850, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.7853 - accuracy: 0.6492 - val_loss: 0.7519 - val_accuracy: 0.6785\n",
      "Epoch 3/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.7252 - accuracy: 0.6925\n",
      "Epoch 00003: val_accuracy improved from 0.67850 to 0.68229, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.7253 - accuracy: 0.6925 - val_loss: 0.7308 - val_accuracy: 0.6823\n",
      "Epoch 4/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.6907 - accuracy: 0.7090\n",
      "Epoch 00004: val_accuracy improved from 0.68229 to 0.69466, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 31s 48ms/step - loss: 0.6907 - accuracy: 0.7090 - val_loss: 0.7149 - val_accuracy: 0.6947\n",
      "Epoch 5/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.6733 - accuracy: 0.7220\n",
      "Epoch 00005: val_accuracy improved from 0.69466 to 0.69641, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.6733 - accuracy: 0.7220 - val_loss: 0.7189 - val_accuracy: 0.6964\n",
      "Epoch 6/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.6542 - accuracy: 0.7328\n",
      "Epoch 00006: val_accuracy improved from 0.69641 to 0.70295, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 31s 48ms/step - loss: 0.6543 - accuracy: 0.7328 - val_loss: 0.6952 - val_accuracy: 0.7030\n",
      "Epoch 7/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.6361 - accuracy: 0.7408\n",
      "Epoch 00007: val_accuracy improved from 0.70295 to 0.70499, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.6361 - accuracy: 0.7408 - val_loss: 0.6917 - val_accuracy: 0.7050\n",
      "Epoch 8/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.6241 - accuracy: 0.7450\n",
      "Epoch 00008: val_accuracy improved from 0.70499 to 0.70878, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.6241 - accuracy: 0.7450 - val_loss: 0.6917 - val_accuracy: 0.7088\n",
      "Epoch 9/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.6177 - accuracy: 0.7501\n",
      "Epoch 00009: val_accuracy improved from 0.70878 to 0.71300, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.6177 - accuracy: 0.7501 - val_loss: 0.6849 - val_accuracy: 0.7130\n",
      "Epoch 10/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.6064 - accuracy: 0.7532\n",
      "Epoch 00010: val_accuracy did not improve from 0.71300\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.6064 - accuracy: 0.7531 - val_loss: 0.6818 - val_accuracy: 0.7118\n",
      "Epoch 11/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5969 - accuracy: 0.7597\n",
      "Epoch 00011: val_accuracy improved from 0.71300 to 0.71576, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5969 - accuracy: 0.7597 - val_loss: 0.6771 - val_accuracy: 0.7158\n",
      "Epoch 12/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5883 - accuracy: 0.7637\n",
      "Epoch 00012: val_accuracy did not improve from 0.71576\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5883 - accuracy: 0.7637 - val_loss: 0.6906 - val_accuracy: 0.7118\n",
      "Epoch 13/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5865 - accuracy: 0.7640\n",
      "Epoch 00013: val_accuracy improved from 0.71576 to 0.71736, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5866 - accuracy: 0.7639 - val_loss: 0.6768 - val_accuracy: 0.7174\n",
      "Epoch 14/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5805 - accuracy: 0.7693\n",
      "Epoch 00014: val_accuracy improved from 0.71736 to 0.71824, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5805 - accuracy: 0.7693 - val_loss: 0.6763 - val_accuracy: 0.7182\n",
      "Epoch 15/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5740 - accuracy: 0.7733\n",
      "Epoch 00015: val_accuracy improved from 0.71824 to 0.71867, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5740 - accuracy: 0.7733 - val_loss: 0.6756 - val_accuracy: 0.7187\n",
      "Epoch 16/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5703 - accuracy: 0.7755\n",
      "Epoch 00016: val_accuracy did not improve from 0.71867\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5702 - accuracy: 0.7755 - val_loss: 0.6881 - val_accuracy: 0.7177\n",
      "Epoch 17/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5763 - accuracy: 0.7710\n",
      "Epoch 00017: val_accuracy improved from 0.71867 to 0.72246, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5763 - accuracy: 0.7710 - val_loss: 0.6745 - val_accuracy: 0.7225\n",
      "Epoch 18/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5664 - accuracy: 0.7782\n",
      "Epoch 00018: val_accuracy did not improve from 0.72246\n",
      "645/645 [==============================] - 30s 46ms/step - loss: 0.5664 - accuracy: 0.7782 - val_loss: 0.6895 - val_accuracy: 0.7198\n",
      "Epoch 19/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5619 - accuracy: 0.7756\n",
      "Epoch 00019: val_accuracy improved from 0.72246 to 0.72551, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5619 - accuracy: 0.7756 - val_loss: 0.6765 - val_accuracy: 0.7255\n",
      "Epoch 20/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5588 - accuracy: 0.7796\n",
      "Epoch 00020: val_accuracy improved from 0.72551 to 0.72610, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5588 - accuracy: 0.7796 - val_loss: 0.6717 - val_accuracy: 0.7261\n",
      "Epoch 21/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5530 - accuracy: 0.7858\n",
      "Epoch 00021: val_accuracy improved from 0.72610 to 0.72624, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5529 - accuracy: 0.7858 - val_loss: 0.6808 - val_accuracy: 0.7262\n",
      "Epoch 22/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5519 - accuracy: 0.7824\n",
      "Epoch 00022: val_accuracy improved from 0.72624 to 0.73002, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5519 - accuracy: 0.7824 - val_loss: 0.6806 - val_accuracy: 0.7300\n",
      "Epoch 23/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5504 - accuracy: 0.7848\n",
      "Epoch 00023: val_accuracy did not improve from 0.73002\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5503 - accuracy: 0.7849 - val_loss: 0.6831 - val_accuracy: 0.7273\n",
      "Epoch 24/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5465 - accuracy: 0.7870\n",
      "Epoch 00024: val_accuracy did not improve from 0.73002\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5465 - accuracy: 0.7870 - val_loss: 0.6759 - val_accuracy: 0.7271\n",
      "Epoch 25/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5430 - accuracy: 0.7868\n",
      "Epoch 00025: val_accuracy did not improve from 0.73002\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5430 - accuracy: 0.7868 - val_loss: 0.6792 - val_accuracy: 0.7254\n",
      "Epoch 26/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5405 - accuracy: 0.7897\n",
      "Epoch 00026: val_accuracy did not improve from 0.73002\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5404 - accuracy: 0.7897 - val_loss: 0.6824 - val_accuracy: 0.7270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5385 - accuracy: 0.7889\n",
      "Epoch 00027: val_accuracy did not improve from 0.73002\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5385 - accuracy: 0.7889 - val_loss: 0.6764 - val_accuracy: 0.7274\n",
      "Epoch 28/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5311 - accuracy: 0.7951\n",
      "Epoch 00028: val_accuracy did not improve from 0.73002\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5311 - accuracy: 0.7951 - val_loss: 0.6818 - val_accuracy: 0.7248\n",
      "Epoch 29/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5331 - accuracy: 0.7947\n",
      "Epoch 00029: val_accuracy did not improve from 0.73002\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5331 - accuracy: 0.7947 - val_loss: 0.6867 - val_accuracy: 0.7281\n",
      "Epoch 30/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5287 - accuracy: 0.7933\n",
      "Epoch 00030: val_accuracy did not improve from 0.73002\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5287 - accuracy: 0.7933 - val_loss: 0.6968 - val_accuracy: 0.7292\n",
      "Epoch 31/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5290 - accuracy: 0.7931\n",
      "Epoch 00031: val_accuracy improved from 0.73002 to 0.73075, saving model to best_model1.hdf5\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5290 - accuracy: 0.7931 - val_loss: 0.6923 - val_accuracy: 0.7308\n",
      "Epoch 32/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5319 - accuracy: 0.7934\n",
      "Epoch 00032: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5319 - accuracy: 0.7934 - val_loss: 0.6967 - val_accuracy: 0.7287\n",
      "Epoch 33/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5241 - accuracy: 0.7939\n",
      "Epoch 00033: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5241 - accuracy: 0.7939 - val_loss: 0.6922 - val_accuracy: 0.7299\n",
      "Epoch 34/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5215 - accuracy: 0.7962\n",
      "Epoch 00034: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 31s 48ms/step - loss: 0.5216 - accuracy: 0.7962 - val_loss: 0.6878 - val_accuracy: 0.7271\n",
      "Epoch 35/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5251 - accuracy: 0.7977\n",
      "Epoch 00035: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5251 - accuracy: 0.7977 - val_loss: 0.6880 - val_accuracy: 0.7283\n",
      "Epoch 36/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5188 - accuracy: 0.8000\n",
      "Epoch 00036: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5188 - accuracy: 0.8000 - val_loss: 0.6975 - val_accuracy: 0.7264\n",
      "Epoch 37/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5153 - accuracy: 0.7998\n",
      "Epoch 00037: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 31s 47ms/step - loss: 0.5152 - accuracy: 0.7999 - val_loss: 0.6938 - val_accuracy: 0.7241\n",
      "Epoch 38/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5142 - accuracy: 0.8012\n",
      "Epoch 00038: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5142 - accuracy: 0.8012 - val_loss: 0.6929 - val_accuracy: 0.7242\n",
      "Epoch 39/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5110 - accuracy: 0.8016\n",
      "Epoch 00039: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5110 - accuracy: 0.8016 - val_loss: 0.6943 - val_accuracy: 0.7284\n",
      "Epoch 40/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5090 - accuracy: 0.8052\n",
      "Epoch 00040: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5090 - accuracy: 0.8052 - val_loss: 0.7020 - val_accuracy: 0.7254\n",
      "Epoch 41/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5070 - accuracy: 0.8027\n",
      "Epoch 00041: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 31s 48ms/step - loss: 0.5070 - accuracy: 0.8027 - val_loss: 0.7092 - val_accuracy: 0.7274\n",
      "Epoch 42/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5036 - accuracy: 0.8063\n",
      "Epoch 00042: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 31s 47ms/step - loss: 0.5036 - accuracy: 0.8063 - val_loss: 0.7015 - val_accuracy: 0.7281\n",
      "Epoch 43/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5076 - accuracy: 0.8035\n",
      "Epoch 00043: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5076 - accuracy: 0.8035 - val_loss: 0.6961 - val_accuracy: 0.7229\n",
      "Epoch 44/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5058 - accuracy: 0.8048\n",
      "Epoch 00044: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5058 - accuracy: 0.8048 - val_loss: 0.7129 - val_accuracy: 0.7281\n",
      "Epoch 45/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5047 - accuracy: 0.8058\n",
      "Epoch 00045: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.5047 - accuracy: 0.8058 - val_loss: 0.7038 - val_accuracy: 0.7267\n",
      "Epoch 46/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5000 - accuracy: 0.8080\n",
      "Epoch 00046: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 31s 47ms/step - loss: 0.5000 - accuracy: 0.8081 - val_loss: 0.7090 - val_accuracy: 0.7236\n",
      "Epoch 47/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5007 - accuracy: 0.8059\n",
      "Epoch 00047: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 31s 47ms/step - loss: 0.5007 - accuracy: 0.8060 - val_loss: 0.7163 - val_accuracy: 0.7294\n",
      "Epoch 48/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4989 - accuracy: 0.8076\n",
      "Epoch 00048: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.4989 - accuracy: 0.8075 - val_loss: 0.7106 - val_accuracy: 0.7235\n",
      "Epoch 49/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.5005 - accuracy: 0.8072\n",
      "Epoch 00049: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 31s 47ms/step - loss: 0.5005 - accuracy: 0.8071 - val_loss: 0.7028 - val_accuracy: 0.7229\n",
      "Epoch 50/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4952 - accuracy: 0.8085\n",
      "Epoch 00050: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 31s 47ms/step - loss: 0.4952 - accuracy: 0.8085 - val_loss: 0.7116 - val_accuracy: 0.7257\n",
      "Epoch 51/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4983 - accuracy: 0.8075\n",
      "Epoch 00051: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.4983 - accuracy: 0.8075 - val_loss: 0.7142 - val_accuracy: 0.7268\n",
      "Epoch 52/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4952 - accuracy: 0.8087\n",
      "Epoch 00052: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.4952 - accuracy: 0.8087 - val_loss: 0.7117 - val_accuracy: 0.7216\n",
      "Epoch 53/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4918 - accuracy: 0.8104\n",
      "Epoch 00053: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.4918 - accuracy: 0.8104 - val_loss: 0.7182 - val_accuracy: 0.7206\n",
      "Epoch 54/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4928 - accuracy: 0.8111\n",
      "Epoch 00054: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.4928 - accuracy: 0.8111 - val_loss: 0.7192 - val_accuracy: 0.7203\n",
      "Epoch 55/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4900 - accuracy: 0.8115\n",
      "Epoch 00055: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 31s 47ms/step - loss: 0.4900 - accuracy: 0.8115 - val_loss: 0.7144 - val_accuracy: 0.7226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4930 - accuracy: 0.8103\n",
      "Epoch 00056: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.4930 - accuracy: 0.8103 - val_loss: 0.7142 - val_accuracy: 0.7245\n",
      "Epoch 57/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4860 - accuracy: 0.8136\n",
      "Epoch 00057: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.4861 - accuracy: 0.8135 - val_loss: 0.7117 - val_accuracy: 0.7207\n",
      "Epoch 58/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4837 - accuracy: 0.8161\n",
      "Epoch 00058: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.4837 - accuracy: 0.8162 - val_loss: 0.7215 - val_accuracy: 0.7191\n",
      "Epoch 59/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4874 - accuracy: 0.8126\n",
      "Epoch 00059: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.4874 - accuracy: 0.8126 - val_loss: 0.7407 - val_accuracy: 0.7236\n",
      "Epoch 60/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4828 - accuracy: 0.8162\n",
      "Epoch 00060: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 31s 47ms/step - loss: 0.4828 - accuracy: 0.8162 - val_loss: 0.7182 - val_accuracy: 0.7241\n",
      "Epoch 61/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4806 - accuracy: 0.8167\n",
      "Epoch 00061: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 31s 48ms/step - loss: 0.4806 - accuracy: 0.8167 - val_loss: 0.7265 - val_accuracy: 0.7235\n",
      "Epoch 62/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4808 - accuracy: 0.8171\n",
      "Epoch 00062: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 32s 49ms/step - loss: 0.4808 - accuracy: 0.8171 - val_loss: 0.7081 - val_accuracy: 0.7190\n",
      "Epoch 63/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4833 - accuracy: 0.8146\n",
      "Epoch 00063: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 32s 49ms/step - loss: 0.4833 - accuracy: 0.8146 - val_loss: 0.7249 - val_accuracy: 0.7209\n",
      "Epoch 64/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4797 - accuracy: 0.8170\n",
      "Epoch 00064: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.4797 - accuracy: 0.8170 - val_loss: 0.7363 - val_accuracy: 0.7248\n",
      "Epoch 65/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4774 - accuracy: 0.8181\n",
      "Epoch 00065: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.4774 - accuracy: 0.8181 - val_loss: 0.7275 - val_accuracy: 0.7225\n",
      "Epoch 66/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4784 - accuracy: 0.8172\n",
      "Epoch 00066: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.4784 - accuracy: 0.8172 - val_loss: 0.7208 - val_accuracy: 0.7171\n",
      "Epoch 67/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4748 - accuracy: 0.8175\n",
      "Epoch 00067: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.4748 - accuracy: 0.8175 - val_loss: 0.7155 - val_accuracy: 0.7161\n",
      "Epoch 68/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4774 - accuracy: 0.8167\n",
      "Epoch 00068: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.4774 - accuracy: 0.8167 - val_loss: 0.7372 - val_accuracy: 0.7220\n",
      "Epoch 69/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4743 - accuracy: 0.8189\n",
      "Epoch 00069: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.4745 - accuracy: 0.8189 - val_loss: 0.7325 - val_accuracy: 0.7174\n",
      "Epoch 70/70\n",
      "644/645 [============================>.] - ETA: 0s - loss: 0.4778 - accuracy: 0.8181\n",
      "Epoch 00070: val_accuracy did not improve from 0.73075\n",
      "645/645 [==============================] - 30s 47ms/step - loss: 0.4778 - accuracy: 0.8180 - val_loss: 0.7158 - val_accuracy: 0.7161\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(layers.Embedding(max_words, 20))\n",
    "model1.add(layers.LSTM(15,dropout=0.5))\n",
    "model1.add(layers.Dense(3,activation='softmax'))\n",
    "\n",
    "model1.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#Implementing model checkpoins to save the best metric and do not lose it on training.\n",
    "checkpoint1 = ModelCheckpoint(\"best_model1.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
    "history = model1.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "534fa846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.9531 - accuracy: 0.5227\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.59322, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 49s 75ms/step - loss: 0.9531 - accuracy: 0.5227 - val_loss: 0.8529 - val_accuracy: 0.5932\n",
      "Epoch 2/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.7748 - accuracy: 0.6613\n",
      "Epoch 00002: val_accuracy improved from 0.59322 to 0.67239, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 39s 61ms/step - loss: 0.7748 - accuracy: 0.6613 - val_loss: 0.7538 - val_accuracy: 0.6724\n",
      "Epoch 3/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.7153 - accuracy: 0.6966\n",
      "Epoch 00003: val_accuracy improved from 0.67239 to 0.69218, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 38s 59ms/step - loss: 0.7153 - accuracy: 0.6966 - val_loss: 0.7212 - val_accuracy: 0.6922\n",
      "Epoch 4/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.6845 - accuracy: 0.7143\n",
      "Epoch 00004: val_accuracy improved from 0.69218 to 0.69291, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 38s 58ms/step - loss: 0.6845 - accuracy: 0.7143 - val_loss: 0.7258 - val_accuracy: 0.6929\n",
      "Epoch 5/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.6604 - accuracy: 0.7260\n",
      "Epoch 00005: val_accuracy improved from 0.69291 to 0.69961, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 38s 59ms/step - loss: 0.6604 - accuracy: 0.7260 - val_loss: 0.7048 - val_accuracy: 0.6996\n",
      "Epoch 6/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.6457 - accuracy: 0.7332\n",
      "Epoch 00006: val_accuracy improved from 0.69961 to 0.70805, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 38s 59ms/step - loss: 0.6457 - accuracy: 0.7332 - val_loss: 0.6817 - val_accuracy: 0.7080\n",
      "Epoch 7/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.6259 - accuracy: 0.7443\n",
      "Epoch 00007: val_accuracy improved from 0.70805 to 0.70936, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 38s 59ms/step - loss: 0.6259 - accuracy: 0.7443 - val_loss: 0.6785 - val_accuracy: 0.7094\n",
      "Epoch 8/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.6166 - accuracy: 0.7506\n",
      "Epoch 00008: val_accuracy improved from 0.70936 to 0.71402, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 38s 59ms/step - loss: 0.6166 - accuracy: 0.7506 - val_loss: 0.6919 - val_accuracy: 0.7140\n",
      "Epoch 9/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.6083 - accuracy: 0.7500\n",
      "Epoch 00009: val_accuracy improved from 0.71402 to 0.71591, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 38s 59ms/step - loss: 0.6083 - accuracy: 0.7500 - val_loss: 0.6761 - val_accuracy: 0.7159\n",
      "Epoch 10/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.6019 - accuracy: 0.7602\n",
      "Epoch 00010: val_accuracy did not improve from 0.71591\n",
      "645/645 [==============================] - 38s 59ms/step - loss: 0.6019 - accuracy: 0.7602 - val_loss: 0.6814 - val_accuracy: 0.7110\n",
      "Epoch 11/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5906 - accuracy: 0.7653\n",
      "Epoch 00011: val_accuracy improved from 0.71591 to 0.72086, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 38s 59ms/step - loss: 0.5906 - accuracy: 0.7653 - val_loss: 0.6694 - val_accuracy: 0.7209\n",
      "Epoch 12/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5853 - accuracy: 0.7681\n",
      "Epoch 00012: val_accuracy did not improve from 0.72086\n",
      "645/645 [==============================] - 38s 59ms/step - loss: 0.5853 - accuracy: 0.7681 - val_loss: 0.6770 - val_accuracy: 0.7172\n",
      "Epoch 13/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5794 - accuracy: 0.7690\n",
      "Epoch 00013: val_accuracy did not improve from 0.72086\n",
      "645/645 [==============================] - 38s 59ms/step - loss: 0.5794 - accuracy: 0.7690 - val_loss: 0.6787 - val_accuracy: 0.7158\n",
      "Epoch 14/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5765 - accuracy: 0.7715\n",
      "Epoch 00014: val_accuracy improved from 0.72086 to 0.72260, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 38s 59ms/step - loss: 0.5765 - accuracy: 0.7715 - val_loss: 0.6868 - val_accuracy: 0.7226\n",
      "Epoch 15/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5675 - accuracy: 0.7750\n",
      "Epoch 00015: val_accuracy did not improve from 0.72260\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.5675 - accuracy: 0.7750 - val_loss: 0.6959 - val_accuracy: 0.7214\n",
      "Epoch 16/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5631 - accuracy: 0.7773\n",
      "Epoch 00016: val_accuracy improved from 0.72260 to 0.72857, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 41s 63ms/step - loss: 0.5631 - accuracy: 0.7773 - val_loss: 0.6722 - val_accuracy: 0.7286\n",
      "Epoch 17/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5602 - accuracy: 0.7805\n",
      "Epoch 00017: val_accuracy did not improve from 0.72857\n",
      "645/645 [==============================] - 40s 63ms/step - loss: 0.5602 - accuracy: 0.7805 - val_loss: 0.6761 - val_accuracy: 0.7261\n",
      "Epoch 18/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5519 - accuracy: 0.7821\n",
      "Epoch 00018: val_accuracy did not improve from 0.72857\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.5519 - accuracy: 0.7821 - val_loss: 0.6814 - val_accuracy: 0.7198\n",
      "Epoch 19/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5492 - accuracy: 0.7869\n",
      "Epoch 00019: val_accuracy did not improve from 0.72857\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.5492 - accuracy: 0.7869 - val_loss: 0.6748 - val_accuracy: 0.7264\n",
      "Epoch 20/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5452 - accuracy: 0.7881\n",
      "Epoch 00020: val_accuracy did not improve from 0.72857\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.5452 - accuracy: 0.7881 - val_loss: 0.6748 - val_accuracy: 0.7276\n",
      "Epoch 21/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5396 - accuracy: 0.7896\n",
      "Epoch 00021: val_accuracy did not improve from 0.72857\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.5396 - accuracy: 0.7896 - val_loss: 0.6888 - val_accuracy: 0.7254\n",
      "Epoch 22/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5400 - accuracy: 0.7899\n",
      "Epoch 00022: val_accuracy did not improve from 0.72857\n",
      "645/645 [==============================] - 38s 59ms/step - loss: 0.5400 - accuracy: 0.7899 - val_loss: 0.6790 - val_accuracy: 0.7286\n",
      "Epoch 23/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5355 - accuracy: 0.7932\n",
      "Epoch 00023: val_accuracy did not improve from 0.72857\n",
      "645/645 [==============================] - 38s 60ms/step - loss: 0.5355 - accuracy: 0.7932 - val_loss: 0.7023 - val_accuracy: 0.7267\n",
      "Epoch 24/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5321 - accuracy: 0.7933\n",
      "Epoch 00024: val_accuracy did not improve from 0.72857\n",
      "645/645 [==============================] - 38s 59ms/step - loss: 0.5321 - accuracy: 0.7933 - val_loss: 0.6913 - val_accuracy: 0.7258\n",
      "Epoch 25/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5274 - accuracy: 0.7937\n",
      "Epoch 00025: val_accuracy did not improve from 0.72857\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.5274 - accuracy: 0.7937 - val_loss: 0.6987 - val_accuracy: 0.7268\n",
      "Epoch 26/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5294 - accuracy: 0.7930\n",
      "Epoch 00026: val_accuracy did not improve from 0.72857\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.5294 - accuracy: 0.7930 - val_loss: 0.6933 - val_accuracy: 0.7257\n",
      "Epoch 27/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5238 - accuracy: 0.7951\n",
      "Epoch 00027: val_accuracy did not improve from 0.72857\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.5238 - accuracy: 0.7951 - val_loss: 0.6905 - val_accuracy: 0.7257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5222 - accuracy: 0.8001\n",
      "Epoch 00028: val_accuracy did not improve from 0.72857\n",
      "645/645 [==============================] - 40s 61ms/step - loss: 0.5222 - accuracy: 0.8001 - val_loss: 0.7023 - val_accuracy: 0.7261\n",
      "Epoch 29/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5189 - accuracy: 0.8012\n",
      "Epoch 00029: val_accuracy did not improve from 0.72857\n",
      "645/645 [==============================] - 39s 61ms/step - loss: 0.5189 - accuracy: 0.8012 - val_loss: 0.6872 - val_accuracy: 0.7252\n",
      "Epoch 30/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5178 - accuracy: 0.7989\n",
      "Epoch 00030: val_accuracy did not improve from 0.72857\n",
      "645/645 [==============================] - 39s 61ms/step - loss: 0.5178 - accuracy: 0.7989 - val_loss: 0.7087 - val_accuracy: 0.7223\n",
      "Epoch 31/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5139 - accuracy: 0.8030\n",
      "Epoch 00031: val_accuracy did not improve from 0.72857\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.5139 - accuracy: 0.8030 - val_loss: 0.7009 - val_accuracy: 0.7259\n",
      "Epoch 32/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5109 - accuracy: 0.8027\n",
      "Epoch 00032: val_accuracy improved from 0.72857 to 0.72988, saving model to best_model2.hdf5\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.5109 - accuracy: 0.8027 - val_loss: 0.6942 - val_accuracy: 0.7299\n",
      "Epoch 33/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5089 - accuracy: 0.8057\n",
      "Epoch 00033: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.5089 - accuracy: 0.8057 - val_loss: 0.7085 - val_accuracy: 0.7271\n",
      "Epoch 34/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5091 - accuracy: 0.8031\n",
      "Epoch 00034: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.5091 - accuracy: 0.8031 - val_loss: 0.7102 - val_accuracy: 0.7209\n",
      "Epoch 35/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5070 - accuracy: 0.8052\n",
      "Epoch 00035: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.5070 - accuracy: 0.8052 - val_loss: 0.7095 - val_accuracy: 0.7239\n",
      "Epoch 36/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5031 - accuracy: 0.8086\n",
      "Epoch 00036: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 61ms/step - loss: 0.5031 - accuracy: 0.8086 - val_loss: 0.7122 - val_accuracy: 0.7235\n",
      "Epoch 37/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.5011 - accuracy: 0.8080\n",
      "Epoch 00037: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.5011 - accuracy: 0.8080 - val_loss: 0.7086 - val_accuracy: 0.7203\n",
      "Epoch 38/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4966 - accuracy: 0.8112\n",
      "Epoch 00038: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 61ms/step - loss: 0.4966 - accuracy: 0.8112 - val_loss: 0.7118 - val_accuracy: 0.7258\n",
      "Epoch 39/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4936 - accuracy: 0.8131\n",
      "Epoch 00039: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 38s 59ms/step - loss: 0.4936 - accuracy: 0.8131 - val_loss: 0.7108 - val_accuracy: 0.7233\n",
      "Epoch 40/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4947 - accuracy: 0.8096\n",
      "Epoch 00040: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 38s 59ms/step - loss: 0.4947 - accuracy: 0.8096 - val_loss: 0.7175 - val_accuracy: 0.7241\n",
      "Epoch 41/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4894 - accuracy: 0.8128\n",
      "Epoch 00041: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 61ms/step - loss: 0.4894 - accuracy: 0.8128 - val_loss: 0.7050 - val_accuracy: 0.7264\n",
      "Epoch 42/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4915 - accuracy: 0.8124\n",
      "Epoch 00042: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 41s 64ms/step - loss: 0.4915 - accuracy: 0.8124 - val_loss: 0.7121 - val_accuracy: 0.7222\n",
      "Epoch 43/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4881 - accuracy: 0.8135\n",
      "Epoch 00043: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 61ms/step - loss: 0.4881 - accuracy: 0.8135 - val_loss: 0.7104 - val_accuracy: 0.7239\n",
      "Epoch 44/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4833 - accuracy: 0.8153\n",
      "Epoch 00044: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 41s 64ms/step - loss: 0.4833 - accuracy: 0.8153 - val_loss: 0.7280 - val_accuracy: 0.7255\n",
      "Epoch 45/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4810 - accuracy: 0.8185\n",
      "Epoch 00045: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 41s 63ms/step - loss: 0.4810 - accuracy: 0.8185 - val_loss: 0.7417 - val_accuracy: 0.7200\n",
      "Epoch 46/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4831 - accuracy: 0.8154\n",
      "Epoch 00046: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 41s 63ms/step - loss: 0.4831 - accuracy: 0.8154 - val_loss: 0.7165 - val_accuracy: 0.7259\n",
      "Epoch 47/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4816 - accuracy: 0.8159\n",
      "Epoch 00047: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.4816 - accuracy: 0.8159 - val_loss: 0.7310 - val_accuracy: 0.7198\n",
      "Epoch 48/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4804 - accuracy: 0.8173\n",
      "Epoch 00048: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 41s 63ms/step - loss: 0.4804 - accuracy: 0.8173 - val_loss: 0.7273 - val_accuracy: 0.7251\n",
      "Epoch 49/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4799 - accuracy: 0.8181\n",
      "Epoch 00049: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 41s 63ms/step - loss: 0.4799 - accuracy: 0.8181 - val_loss: 0.7300 - val_accuracy: 0.7274\n",
      "Epoch 50/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4712 - accuracy: 0.8224\n",
      "Epoch 00050: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 40s 62ms/step - loss: 0.4712 - accuracy: 0.8224 - val_loss: 0.7253 - val_accuracy: 0.7242\n",
      "Epoch 51/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4743 - accuracy: 0.8207\n",
      "Epoch 00051: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 41s 63ms/step - loss: 0.4743 - accuracy: 0.8207 - val_loss: 0.7187 - val_accuracy: 0.7203\n",
      "Epoch 52/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4718 - accuracy: 0.8196\n",
      "Epoch 00052: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.4718 - accuracy: 0.8196 - val_loss: 0.7248 - val_accuracy: 0.7220\n",
      "Epoch 53/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4689 - accuracy: 0.8230\n",
      "Epoch 00053: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.4689 - accuracy: 0.8230 - val_loss: 0.7284 - val_accuracy: 0.7249\n",
      "Epoch 54/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4685 - accuracy: 0.8212\n",
      "Epoch 00054: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.4685 - accuracy: 0.8212 - val_loss: 0.7332 - val_accuracy: 0.7284\n",
      "Epoch 55/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4692 - accuracy: 0.8227\n",
      "Epoch 00055: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.4692 - accuracy: 0.8227 - val_loss: 0.7304 - val_accuracy: 0.7216\n",
      "Epoch 56/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4645 - accuracy: 0.8233\n",
      "Epoch 00056: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.4645 - accuracy: 0.8233 - val_loss: 0.7330 - val_accuracy: 0.7204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4649 - accuracy: 0.8247\n",
      "Epoch 00057: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.4649 - accuracy: 0.8247 - val_loss: 0.7326 - val_accuracy: 0.7115\n",
      "Epoch 58/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4641 - accuracy: 0.8242\n",
      "Epoch 00058: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.4641 - accuracy: 0.8242 - val_loss: 0.7413 - val_accuracy: 0.7241\n",
      "Epoch 59/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4615 - accuracy: 0.8282\n",
      "Epoch 00059: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.4615 - accuracy: 0.8282 - val_loss: 0.7421 - val_accuracy: 0.7149\n",
      "Epoch 60/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4570 - accuracy: 0.8254\n",
      "Epoch 00060: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 61ms/step - loss: 0.4570 - accuracy: 0.8254 - val_loss: 0.7482 - val_accuracy: 0.7149\n",
      "Epoch 61/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4577 - accuracy: 0.8272\n",
      "Epoch 00061: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.4577 - accuracy: 0.8272 - val_loss: 0.7471 - val_accuracy: 0.7217\n",
      "Epoch 62/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4584 - accuracy: 0.8233\n",
      "Epoch 00062: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.4584 - accuracy: 0.8233 - val_loss: 0.7597 - val_accuracy: 0.7127\n",
      "Epoch 63/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4539 - accuracy: 0.8308\n",
      "Epoch 00063: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.4539 - accuracy: 0.8308 - val_loss: 0.7478 - val_accuracy: 0.7187\n",
      "Epoch 64/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4489 - accuracy: 0.8339\n",
      "Epoch 00064: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.4489 - accuracy: 0.8339 - val_loss: 0.7439 - val_accuracy: 0.7195\n",
      "Epoch 65/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4526 - accuracy: 0.8290\n",
      "Epoch 00065: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.4526 - accuracy: 0.8290 - val_loss: 0.7643 - val_accuracy: 0.7166\n",
      "Epoch 66/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4523 - accuracy: 0.8288\n",
      "Epoch 00066: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 61ms/step - loss: 0.4523 - accuracy: 0.8288 - val_loss: 0.7536 - val_accuracy: 0.7213\n",
      "Epoch 67/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4507 - accuracy: 0.8301\n",
      "Epoch 00067: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 61ms/step - loss: 0.4507 - accuracy: 0.8301 - val_loss: 0.7528 - val_accuracy: 0.7140\n",
      "Epoch 68/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4474 - accuracy: 0.8321\n",
      "Epoch 00068: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.4474 - accuracy: 0.8321 - val_loss: 0.7543 - val_accuracy: 0.7121\n",
      "Epoch 69/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4451 - accuracy: 0.8327\n",
      "Epoch 00069: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.4451 - accuracy: 0.8327 - val_loss: 0.7538 - val_accuracy: 0.7134\n",
      "Epoch 70/70\n",
      "645/645 [==============================] - ETA: 0s - loss: 0.4422 - accuracy: 0.8345\n",
      "Epoch 00070: val_accuracy did not improve from 0.72988\n",
      "645/645 [==============================] - 39s 60ms/step - loss: 0.4422 - accuracy: 0.8345 - val_loss: 0.7592 - val_accuracy: 0.7213\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
    "model2.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))\n",
    "model2.add(layers.Dense(3,activation='softmax'))\n",
    "model2.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#Implementing model checkpoins to save the best metric and do not lose it on training.\n",
    "checkpoint2 = ModelCheckpoint(\"best_model2.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
    "history = model2.fit(X_train, y_train, epochs=70,validation_data=(X_test, y_test),callbacks=[checkpoint2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a0f0b2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = keras.models.load_model(\"best_model2.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd17ef33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/215 - 2s - loss: 0.6942 - accuracy: 0.7299\n",
      "Model accuracy:  0.7298792004585266\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = best_model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Model accuracy: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56a0379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8627201a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 3190: expected 8 fields, saw 17\\nSkipping line 3201: expected 8 fields, saw 17\\nSkipping line 3251: expected 8 fields, saw 17\\nSkipping line 3516: expected 8 fields, saw 17\\nSkipping line 4074: expected 8 fields, saw 17\\nSkipping line 4083: expected 8 fields, saw 17\\nSkipping line 4084: expected 8 fields, saw 17\\nSkipping line 4495: expected 8 fields, saw 12\\n'\n"
     ]
    }
   ],
   "source": [
    "train2 = pd.read_csv('stockerbot-export.csv',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "07638cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28264, 8)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "43bc518a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2 = train2[['text']]\n",
    "train2[\"text\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "edefde21",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "data_to_list = train2['text'].values.tolist()\n",
    "for i in range(len(data_to_list)):\n",
    "    temp.append(depure_data(data_to_list[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "14078805",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words = list(sent_to_words(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "73605500",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(len(data_words)):\n",
    "    data.append(detokenize(data_words[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "114ab69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2['text']=data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "06ef2fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Alkou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "new_words = {\n",
    "    'foo': 2.0,\n",
    "    'bar': -3.4,\n",
    "}\n",
    "\n",
    "SIA = SentimentIntensityAnalyzer()\n",
    "\n",
    "SIA.lexicon.update(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8057a019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findpolarity(data):\n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    polarity = sid.polarity_scores(data)\n",
    "    if(polarity['compound'] >= 0.2):  \n",
    "        sentiment = 'positive'\n",
    "    if(polarity['compound'] <= -0.2):\n",
    "        sentiment = 'negative'\n",
    "    if(polarity['compound'] < 0.2 and polarity['compound'] >-0.2):\n",
    "        sentiment = 'neutral'     \n",
    "    return(sentiment)\n",
    "\n",
    "sentiment=[]\n",
    "for tweet in train2['text']:\n",
    "    s = findpolarity(tweet)\n",
    "    sentiment.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d6a731be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28264"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f49a047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2['sentiment']=sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1902a4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train2.to_csv('tweet_sentiment_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a3209b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have created our new financial tweet dataset and are going to train our model on that one\n",
    "train = pd.read_csv('tweet_sentiment_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "50f78758",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "#Splitting pd.Series to list\n",
    "data_to_list = train['text'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "06f356dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "57d56ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(train['sentiment'])\n",
    "y = []\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 'neutral':\n",
    "        y.append(0)\n",
    "    if labels[i] == 'negative':\n",
    "        y.append(1)\n",
    "    if labels[i] == 'positive':\n",
    "        y.append(2)\n",
    "y = np.array(y)\n",
    "labels = tf.keras.utils.to_categorical(y, 3, dtype=\"float32\")\n",
    "del y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "36cd56cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0 ...  381  381 3022]\n",
      " [   0    0    0 ...    9  346 3766]\n",
      " [   0    0    0 ...  315    9 3767]\n",
      " ...\n",
      " [   0    0    0 ...  273  133  327]\n",
      " [   0    0    0 ... 4466 4467  133]\n",
      " [   0    0    0 ...    2  815  157]]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data)\n",
    "sequences = tokenizer.texts_to_sequences(data)\n",
    "tweets = pad_sequences(sequences, maxlen=max_len)\n",
    "print(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4c9d6cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21198 7066 21198 7066\n"
     ]
    }
   ],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(tweets,labels, random_state=0)\n",
    "print (len(X_train2),len(X_test2),len(y_train2),len(y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8f086a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.6577 - accuracy: 0.7312\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80512, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 51s 76ms/step - loss: 0.6577 - accuracy: 0.7312 - val_loss: 0.5027 - val_accuracy: 0.8051\n",
      "Epoch 2/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.4193 - accuracy: 0.8471\n",
      "Epoch 00002: val_accuracy improved from 0.80512 to 0.87263, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 48s 73ms/step - loss: 0.4193 - accuracy: 0.8471 - val_loss: 0.3577 - val_accuracy: 0.8726\n",
      "Epoch 3/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.3258 - accuracy: 0.8875\n",
      "Epoch 00003: val_accuracy improved from 0.87263 to 0.90051, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 49s 73ms/step - loss: 0.3258 - accuracy: 0.8875 - val_loss: 0.2993 - val_accuracy: 0.9005\n",
      "Epoch 4/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.2821 - accuracy: 0.9058\n",
      "Epoch 00004: val_accuracy improved from 0.90051 to 0.90688, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 49s 74ms/step - loss: 0.2821 - accuracy: 0.9058 - val_loss: 0.2754 - val_accuracy: 0.9069\n",
      "Epoch 5/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.2550 - accuracy: 0.9134\n",
      "Epoch 00005: val_accuracy improved from 0.90688 to 0.91381, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 49s 74ms/step - loss: 0.2550 - accuracy: 0.9134 - val_loss: 0.2570 - val_accuracy: 0.9138\n",
      "Epoch 6/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.2382 - accuracy: 0.9200\n",
      "Epoch 00006: val_accuracy improved from 0.91381 to 0.91792, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 49s 73ms/step - loss: 0.2382 - accuracy: 0.9200 - val_loss: 0.2469 - val_accuracy: 0.9179\n",
      "Epoch 7/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.2227 - accuracy: 0.9270\n",
      "Epoch 00007: val_accuracy improved from 0.91792 to 0.92160, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 49s 74ms/step - loss: 0.2227 - accuracy: 0.9270 - val_loss: 0.2384 - val_accuracy: 0.9216\n",
      "Epoch 8/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.2147 - accuracy: 0.9299\n",
      "Epoch 00008: val_accuracy improved from 0.92160 to 0.92499, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 49s 73ms/step - loss: 0.2147 - accuracy: 0.9299 - val_loss: 0.2351 - val_accuracy: 0.9250\n",
      "Epoch 9/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.2029 - accuracy: 0.9334\n",
      "Epoch 00009: val_accuracy improved from 0.92499 to 0.92768, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 48s 73ms/step - loss: 0.2029 - accuracy: 0.9334 - val_loss: 0.2334 - val_accuracy: 0.9277\n",
      "Epoch 10/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1954 - accuracy: 0.9357 ETA: 1s\n",
      "Epoch 00010: val_accuracy improved from 0.92768 to 0.92980, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 48s 73ms/step - loss: 0.1954 - accuracy: 0.9357 - val_loss: 0.2210 - val_accuracy: 0.9298\n",
      "Epoch 11/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1887 - accuracy: 0.9401\n",
      "Epoch 00011: val_accuracy improved from 0.92980 to 0.93193, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 48s 73ms/step - loss: 0.1887 - accuracy: 0.9401 - val_loss: 0.2221 - val_accuracy: 0.9319\n",
      "Epoch 12/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1829 - accuracy: 0.9422\n",
      "Epoch 00012: val_accuracy improved from 0.93193 to 0.93264, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 49s 73ms/step - loss: 0.1829 - accuracy: 0.9422 - val_loss: 0.2159 - val_accuracy: 0.9326\n",
      "Epoch 13/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1795 - accuracy: 0.9419\n",
      "Epoch 00013: val_accuracy improved from 0.93264 to 0.93419, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 49s 73ms/step - loss: 0.1795 - accuracy: 0.9419 - val_loss: 0.2138 - val_accuracy: 0.9342\n",
      "Epoch 14/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1790 - accuracy: 0.9430\n",
      "Epoch 00014: val_accuracy improved from 0.93419 to 0.93462, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 48s 73ms/step - loss: 0.1790 - accuracy: 0.9430 - val_loss: 0.2106 - val_accuracy: 0.9346\n",
      "Epoch 15/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1721 - accuracy: 0.9449\n",
      "Epoch 00015: val_accuracy improved from 0.93462 to 0.93603, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 49s 73ms/step - loss: 0.1721 - accuracy: 0.9449 - val_loss: 0.2100 - val_accuracy: 0.9360\n",
      "Epoch 16/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.9460\n",
      "Epoch 00016: val_accuracy did not improve from 0.93603\n",
      "663/663 [==============================] - 48s 73ms/step - loss: 0.1694 - accuracy: 0.9460 - val_loss: 0.2085 - val_accuracy: 0.9356\n",
      "Epoch 17/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1663 - accuracy: 0.9469\n",
      "Epoch 00017: val_accuracy improved from 0.93603 to 0.93702, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 48s 73ms/step - loss: 0.1663 - accuracy: 0.9469 - val_loss: 0.2034 - val_accuracy: 0.9370\n",
      "Epoch 18/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1610 - accuracy: 0.9491\n",
      "Epoch 00018: val_accuracy improved from 0.93702 to 0.93815, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 48s 73ms/step - loss: 0.1610 - accuracy: 0.9491 - val_loss: 0.2040 - val_accuracy: 0.9382\n",
      "Epoch 19/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1627 - accuracy: 0.9491\n",
      "Epoch 00019: val_accuracy did not improve from 0.93815\n",
      "663/663 [==============================] - 48s 73ms/step - loss: 0.1627 - accuracy: 0.9491 - val_loss: 0.2101 - val_accuracy: 0.9370\n",
      "Epoch 20/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1606 - accuracy: 0.9492\n",
      "Epoch 00020: val_accuracy improved from 0.93815 to 0.93943, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 48s 73ms/step - loss: 0.1606 - accuracy: 0.9492 - val_loss: 0.1986 - val_accuracy: 0.9394\n",
      "Epoch 21/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1584 - accuracy: 0.9504\n",
      "Epoch 00021: val_accuracy did not improve from 0.93943\n",
      "663/663 [==============================] - 48s 72ms/step - loss: 0.1584 - accuracy: 0.9504 - val_loss: 0.2052 - val_accuracy: 0.9389\n",
      "Epoch 22/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1596 - accuracy: 0.9507\n",
      "Epoch 00022: val_accuracy improved from 0.93943 to 0.93957, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 48s 72ms/step - loss: 0.1596 - accuracy: 0.9507 - val_loss: 0.2009 - val_accuracy: 0.9396\n",
      "Epoch 23/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1571 - accuracy: 0.9511\n",
      "Epoch 00023: val_accuracy improved from 0.93957 to 0.94141, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 48s 72ms/step - loss: 0.1571 - accuracy: 0.9511 - val_loss: 0.1971 - val_accuracy: 0.9414\n",
      "Epoch 24/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1554 - accuracy: 0.9509\n",
      "Epoch 00024: val_accuracy did not improve from 0.94141\n",
      "663/663 [==============================] - 48s 72ms/step - loss: 0.1554 - accuracy: 0.9509 - val_loss: 0.2039 - val_accuracy: 0.9414\n",
      "Epoch 25/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1539 - accuracy: 0.9508\n",
      "Epoch 00025: val_accuracy did not improve from 0.94141\n",
      "663/663 [==============================] - 47s 72ms/step - loss: 0.1539 - accuracy: 0.9508 - val_loss: 0.2064 - val_accuracy: 0.9411\n",
      "Epoch 26/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1513 - accuracy: 0.9524\n",
      "Epoch 00026: val_accuracy improved from 0.94141 to 0.94198, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 47s 72ms/step - loss: 0.1513 - accuracy: 0.9524 - val_loss: 0.1989 - val_accuracy: 0.9420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1523 - accuracy: 0.9517\n",
      "Epoch 00027: val_accuracy improved from 0.94198 to 0.94523, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 48s 72ms/step - loss: 0.1523 - accuracy: 0.9517 - val_loss: 0.1990 - val_accuracy: 0.9452\n",
      "Epoch 28/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1515 - accuracy: 0.9509\n",
      "Epoch 00028: val_accuracy did not improve from 0.94523\n",
      "663/663 [==============================] - 48s 72ms/step - loss: 0.1515 - accuracy: 0.9509 - val_loss: 0.1922 - val_accuracy: 0.9449\n",
      "Epoch 29/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1453 - accuracy: 0.9531\n",
      "Epoch 00029: val_accuracy improved from 0.94523 to 0.94551, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 48s 72ms/step - loss: 0.1453 - accuracy: 0.9531 - val_loss: 0.1968 - val_accuracy: 0.9455\n",
      "Epoch 30/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1481 - accuracy: 0.9532\n",
      "Epoch 00030: val_accuracy did not improve from 0.94551\n",
      "663/663 [==============================] - 47s 72ms/step - loss: 0.1481 - accuracy: 0.9532 - val_loss: 0.2024 - val_accuracy: 0.9417\n",
      "Epoch 31/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1475 - accuracy: 0.9538\n",
      "Epoch 00031: val_accuracy did not improve from 0.94551\n",
      "663/663 [==============================] - 47s 71ms/step - loss: 0.1475 - accuracy: 0.9538 - val_loss: 0.2032 - val_accuracy: 0.9417\n",
      "Epoch 32/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1470 - accuracy: 0.9549\n",
      "Epoch 00032: val_accuracy did not improve from 0.94551\n",
      "663/663 [==============================] - 47s 72ms/step - loss: 0.1470 - accuracy: 0.9549 - val_loss: 0.2026 - val_accuracy: 0.9438\n",
      "Epoch 33/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1464 - accuracy: 0.9533\n",
      "Epoch 00033: val_accuracy improved from 0.94551 to 0.94580, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 47s 71ms/step - loss: 0.1464 - accuracy: 0.9533 - val_loss: 0.1953 - val_accuracy: 0.9458\n",
      "Epoch 34/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1409 - accuracy: 0.9564\n",
      "Epoch 00034: val_accuracy improved from 0.94580 to 0.94636, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 47s 71ms/step - loss: 0.1409 - accuracy: 0.9564 - val_loss: 0.1914 - val_accuracy: 0.9464\n",
      "Epoch 35/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1403 - accuracy: 0.9565\n",
      "Epoch 00035: val_accuracy did not improve from 0.94636\n",
      "663/663 [==============================] - 47s 71ms/step - loss: 0.1403 - accuracy: 0.9565 - val_loss: 0.1951 - val_accuracy: 0.9464\n",
      "Epoch 36/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1423 - accuracy: 0.9552\n",
      "Epoch 00036: val_accuracy improved from 0.94636 to 0.94650, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 47s 71ms/step - loss: 0.1423 - accuracy: 0.9552 - val_loss: 0.1948 - val_accuracy: 0.9465\n",
      "Epoch 37/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1415 - accuracy: 0.9551\n",
      "Epoch 00037: val_accuracy did not improve from 0.94650\n",
      "663/663 [==============================] - 47s 71ms/step - loss: 0.1415 - accuracy: 0.9551 - val_loss: 0.1931 - val_accuracy: 0.9465\n",
      "Epoch 38/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1406 - accuracy: 0.9550\n",
      "Epoch 00038: val_accuracy did not improve from 0.94650\n",
      "663/663 [==============================] - 47s 71ms/step - loss: 0.1406 - accuracy: 0.9550 - val_loss: 0.2067 - val_accuracy: 0.9437\n",
      "Epoch 39/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1389 - accuracy: 0.9569\n",
      "Epoch 00039: val_accuracy did not improve from 0.94650\n",
      "663/663 [==============================] - 47s 70ms/step - loss: 0.1389 - accuracy: 0.9569 - val_loss: 0.1958 - val_accuracy: 0.9455\n",
      "Epoch 40/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1403 - accuracy: 0.9553\n",
      "Epoch 00040: val_accuracy did not improve from 0.94650\n",
      "663/663 [==============================] - 47s 70ms/step - loss: 0.1403 - accuracy: 0.9553 - val_loss: 0.1916 - val_accuracy: 0.9462\n",
      "Epoch 41/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1395 - accuracy: 0.9556\n",
      "Epoch 00041: val_accuracy improved from 0.94650 to 0.94693, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 47s 70ms/step - loss: 0.1395 - accuracy: 0.9556 - val_loss: 0.1946 - val_accuracy: 0.9469\n",
      "Epoch 42/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1351 - accuracy: 0.9576\n",
      "Epoch 00042: val_accuracy did not improve from 0.94693\n",
      "663/663 [==============================] - 47s 70ms/step - loss: 0.1351 - accuracy: 0.9576 - val_loss: 0.1937 - val_accuracy: 0.9455\n",
      "Epoch 43/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1391 - accuracy: 0.9566\n",
      "Epoch 00043: val_accuracy improved from 0.94693 to 0.94735, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 47s 70ms/step - loss: 0.1391 - accuracy: 0.9566 - val_loss: 0.1935 - val_accuracy: 0.9474\n",
      "Epoch 44/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1374 - accuracy: 0.9571\n",
      "Epoch 00044: val_accuracy did not improve from 0.94735\n",
      "663/663 [==============================] - 47s 70ms/step - loss: 0.1374 - accuracy: 0.9571 - val_loss: 0.1950 - val_accuracy: 0.9461\n",
      "Epoch 45/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1369 - accuracy: 0.9565\n",
      "Epoch 00045: val_accuracy did not improve from 0.94735\n",
      "663/663 [==============================] - 47s 70ms/step - loss: 0.1369 - accuracy: 0.9565 - val_loss: 0.1959 - val_accuracy: 0.9472\n",
      "Epoch 46/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1349 - accuracy: 0.9575\n",
      "Epoch 00046: val_accuracy did not improve from 0.94735\n",
      "663/663 [==============================] - 47s 70ms/step - loss: 0.1349 - accuracy: 0.9575 - val_loss: 0.1954 - val_accuracy: 0.9469\n",
      "Epoch 47/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1374 - accuracy: 0.9549\n",
      "Epoch 00047: val_accuracy did not improve from 0.94735\n",
      "663/663 [==============================] - 46s 70ms/step - loss: 0.1374 - accuracy: 0.9549 - val_loss: 0.1970 - val_accuracy: 0.9457\n",
      "Epoch 48/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1316 - accuracy: 0.9575\n",
      "Epoch 00048: val_accuracy did not improve from 0.94735\n",
      "663/663 [==============================] - 47s 70ms/step - loss: 0.1316 - accuracy: 0.9575 - val_loss: 0.2024 - val_accuracy: 0.9421\n",
      "Epoch 49/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1342 - accuracy: 0.9575\n",
      "Epoch 00049: val_accuracy did not improve from 0.94735\n",
      "663/663 [==============================] - 47s 70ms/step - loss: 0.1342 - accuracy: 0.9575 - val_loss: 0.1998 - val_accuracy: 0.9428\n",
      "Epoch 50/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1328 - accuracy: 0.9570\n",
      "Epoch 00050: val_accuracy did not improve from 0.94735\n",
      "663/663 [==============================] - 47s 70ms/step - loss: 0.1328 - accuracy: 0.9570 - val_loss: 0.2061 - val_accuracy: 0.9432\n",
      "Epoch 51/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1325 - accuracy: 0.9566\n",
      "Epoch 00051: val_accuracy did not improve from 0.94735\n",
      "663/663 [==============================] - 46s 70ms/step - loss: 0.1325 - accuracy: 0.9566 - val_loss: 0.1908 - val_accuracy: 0.9447\n",
      "Epoch 52/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1327 - accuracy: 0.9583\n",
      "Epoch 00052: val_accuracy improved from 0.94735 to 0.94750, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 46s 70ms/step - loss: 0.1327 - accuracy: 0.9583 - val_loss: 0.1845 - val_accuracy: 0.9475\n",
      "Epoch 53/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1304 - accuracy: 0.9596\n",
      "Epoch 00053: val_accuracy did not improve from 0.94750\n",
      "663/663 [==============================] - 46s 70ms/step - loss: 0.1304 - accuracy: 0.9596 - val_loss: 0.1973 - val_accuracy: 0.9464\n",
      "Epoch 54/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1301 - accuracy: 0.9598\n",
      "Epoch 00054: val_accuracy did not improve from 0.94750\n",
      "663/663 [==============================] - 46s 70ms/step - loss: 0.1301 - accuracy: 0.9598 - val_loss: 0.1950 - val_accuracy: 0.9471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1318 - accuracy: 0.9587\n",
      "Epoch 00055: val_accuracy did not improve from 0.94750\n",
      "663/663 [==============================] - 47s 70ms/step - loss: 0.1318 - accuracy: 0.9587 - val_loss: 0.1996 - val_accuracy: 0.9449\n",
      "Epoch 56/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1319 - accuracy: 0.9571\n",
      "Epoch 00056: val_accuracy improved from 0.94750 to 0.94792, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 47s 70ms/step - loss: 0.1319 - accuracy: 0.9571 - val_loss: 0.1945 - val_accuracy: 0.9479\n",
      "Epoch 57/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1321 - accuracy: 0.9582\n",
      "Epoch 00057: val_accuracy did not improve from 0.94792\n",
      "663/663 [==============================] - 46s 70ms/step - loss: 0.1321 - accuracy: 0.9582 - val_loss: 0.1908 - val_accuracy: 0.9472\n",
      "Epoch 58/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1270 - accuracy: 0.9595\n",
      "Epoch 00058: val_accuracy did not improve from 0.94792\n",
      "663/663 [==============================] - 46s 70ms/step - loss: 0.1270 - accuracy: 0.9595 - val_loss: 0.1933 - val_accuracy: 0.9464\n",
      "Epoch 59/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1282 - accuracy: 0.9593\n",
      "Epoch 00059: val_accuracy did not improve from 0.94792\n",
      "663/663 [==============================] - 46s 70ms/step - loss: 0.1282 - accuracy: 0.9593 - val_loss: 0.1918 - val_accuracy: 0.9455\n",
      "Epoch 60/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1325 - accuracy: 0.9586\n",
      "Epoch 00060: val_accuracy did not improve from 0.94792\n",
      "663/663 [==============================] - 46s 70ms/step - loss: 0.1325 - accuracy: 0.9586 - val_loss: 0.1964 - val_accuracy: 0.9431\n",
      "Epoch 61/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1286 - accuracy: 0.9595\n",
      "Epoch 00061: val_accuracy did not improve from 0.94792\n",
      "663/663 [==============================] - 46s 70ms/step - loss: 0.1286 - accuracy: 0.9595 - val_loss: 0.1900 - val_accuracy: 0.9476\n",
      "Epoch 62/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1292 - accuracy: 0.9588\n",
      "Epoch 00062: val_accuracy improved from 0.94792 to 0.94877, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 46s 70ms/step - loss: 0.1292 - accuracy: 0.9588 - val_loss: 0.1900 - val_accuracy: 0.9488\n",
      "Epoch 63/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1252 - accuracy: 0.9602\n",
      "Epoch 00063: val_accuracy did not improve from 0.94877\n",
      "663/663 [==============================] - 46s 70ms/step - loss: 0.1252 - accuracy: 0.9602 - val_loss: 0.1957 - val_accuracy: 0.9432\n",
      "Epoch 64/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1249 - accuracy: 0.9596\n",
      "Epoch 00064: val_accuracy did not improve from 0.94877\n",
      "663/663 [==============================] - 46s 70ms/step - loss: 0.1249 - accuracy: 0.9596 - val_loss: 0.1913 - val_accuracy: 0.9474\n",
      "Epoch 65/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1308 - accuracy: 0.9580\n",
      "Epoch 00065: val_accuracy improved from 0.94877 to 0.94919, saving model to best_model2.hdf5\n",
      "663/663 [==============================] - 46s 70ms/step - loss: 0.1308 - accuracy: 0.9580 - val_loss: 0.1902 - val_accuracy: 0.9492\n",
      "Epoch 66/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1281 - accuracy: 0.9589\n",
      "Epoch 00066: val_accuracy did not improve from 0.94919\n",
      "663/663 [==============================] - 46s 70ms/step - loss: 0.1281 - accuracy: 0.9589 - val_loss: 0.1950 - val_accuracy: 0.9469\n",
      "Epoch 67/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1264 - accuracy: 0.9602\n",
      "Epoch 00067: val_accuracy did not improve from 0.94919\n",
      "663/663 [==============================] - 46s 70ms/step - loss: 0.1264 - accuracy: 0.9602 - val_loss: 0.1909 - val_accuracy: 0.9476\n",
      "Epoch 68/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1244 - accuracy: 0.9611\n",
      "Epoch 00068: val_accuracy did not improve from 0.94919\n",
      "663/663 [==============================] - 46s 70ms/step - loss: 0.1244 - accuracy: 0.9611 - val_loss: 0.1919 - val_accuracy: 0.9481\n",
      "Epoch 69/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1276 - accuracy: 0.9596\n",
      "Epoch 00069: val_accuracy did not improve from 0.94919\n",
      "663/663 [==============================] - 46s 70ms/step - loss: 0.1276 - accuracy: 0.9596 - val_loss: 0.1926 - val_accuracy: 0.9481\n",
      "Epoch 70/70\n",
      "663/663 [==============================] - ETA: 0s - loss: 0.1259 - accuracy: 0.9593\n",
      "Epoch 00070: val_accuracy did not improve from 0.94919\n",
      "663/663 [==============================] - 46s 70ms/step - loss: 0.1259 - accuracy: 0.9593 - val_loss: 0.1940 - val_accuracy: 0.9476\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
    "model2.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))\n",
    "model2.add(layers.Dense(3,activation='softmax'))\n",
    "model2.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#Implementing model checkpoins to save the best metric and do not lose it on training.\n",
    "checkpoint2 = ModelCheckpoint(\"best_model2.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)\n",
    "history = model2.fit(X_train2, y_train2, epochs=70,validation_data=(X_test2, y_test2),callbacks=[checkpoint2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "61a35068",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = keras.models.load_model(\"best_model2.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "ff33cb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221/221 - 2s - loss: 0.1902 - accuracy: 0.9492\n",
      "7066\n",
      "Model accuracy:  0.9491932988166809\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = best_model.evaluate(X_test2, y_test2, verbose=2)\n",
    "print('Model accuracy: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "03cc1af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0  133    9  406    1 1904   10  125  208\n",
      "     3  232 1485  599]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'negative'"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence = tokenizer.texts_to_sequences(['BTC is going to decrease in value over the next three days'])\n",
    "test = pad_sequences(sequence, maxlen=max_len)\n",
    "print(test)\n",
    "sentiment[np.around(best_model.predict(test), decimals=0).argmax(axis=1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "70537612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "predictions = best_model.predict(X_test2)\n",
    "print((y_test2[:40]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55850d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
