{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be1df491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing stuff on run\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "#nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from numpy import loadtxt\n",
    "import twitter\n",
    "import csv\n",
    "import pandas as pd\n",
    "import json\n",
    "import statsmodels.tsa.api as smt\n",
    "import statsmodels.api as sm\n",
    "from tqdm import tqdm_notebook\n",
    "from itertools import product\n",
    "import yfinance as yf\n",
    "from statsmodels.tsa.arima.model import ARIMAResults\n",
    "import datetime\n",
    "import time\n",
    "loadedmodel = ARIMAResults.load('bestTimeSeriesModel2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d40830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIA = SentimentIntensityAnalyzer()\n",
    "Financial_Lexicon = {\n",
    "    'apr': -0.5,\n",
    "    'accrue': 1.0,\n",
    "    'amortisation': -1.0,\n",
    "    'appreciation' : 1.6,\n",
    "    'asset' : 0.5,\n",
    "    'stripping' : -1.2,\n",
    "    'ath' : 1.0,\n",
    "    'bagholder' : -2.0,\n",
    "    'bear' : -1.0,\n",
    "    'bearish' : -1.6,\n",
    "    'bull' : 1.0,\n",
    "    'bullish' : 1.9, \n",
    "    'bluechip' : 1.0,\n",
    "    'bubble' : -2.7,\n",
    "    'buy' : 3.2,\n",
    "    'cdo' : -1.0,\n",
    "    'ccj' : -1.0,\n",
    "    'commission' : -0.5,\n",
    "    'contagion' : -1.0,\n",
    "    'deflation' : -0.7,\n",
    "    'deflated' : -0.8,\n",
    "    'depreciation': -0.6,\n",
    "    'deprecated': -1.7,\n",
    "    'dog' : -2.2,\n",
    "    'crash' : -3.2,\n",
    "    'crashing' : -3.4,\n",
    "    'fomo' : -1.4,\n",
    "    'fud' : 1.6,\n",
    "    'takeover' : -1.2,\n",
    "    'scheme' : -2.4,\n",
    "    'liquidity' : 1.6,\n",
    "    'inflation' : -0.6,\n",
    "    'junk' : -0.7,\n",
    "    'unprofitable' : -1.8,\n",
    "    'unstable' : -1.2,\n",
    "    'long' : 0.9,\n",
    "    'capitalisation' : 0.3,\n",
    "    'premium' : 0.7,\n",
    "    'pump' : -0.4,\n",
    "    'dump' : -0.7,\n",
    "    'return' : 1.5,\n",
    "    'sheep' : -2.4,\n",
    "    'underweight' : -0.5,\n",
    "    'whipsaw' : -0.4,\n",
    "    'yield' : 0.8,\n",
    "    'absence' : -0.4,\n",
    "    'accepted' : 0.8,\n",
    "    'advances' : 1.0,\n",
    "    'advocate' : 0.6,\n",
    "    'alert' : -0.4,\n",
    "    'alerts' : -0.4,\n",
    "    'angry' : -1.2,\n",
    "    'appointed' : 0.2,\n",
    "    'appreciation' : 0.8,\n",
    "    'approvals' : 1.2,\n",
    "    'automate' : 0.3,\n",
    "    'awards' : 1.2,\n",
    "    'below' : -0.5,\n",
    "    'benefits' : 0.4,\n",
    "    'best' : 1.7,\n",
    "    'bet' : 0.6,\n",
    "    'bid' : 0.4,\n",
    "    'bleed' : -1.7,\n",
    "    'bloomberg' : 0.2,\n",
    "    'brave' : 0.6,\n",
    "    'breaking' : 0.4,\n",
    "    'catalysts' : 0.6,\n",
    "    'celebration' : 1.4,\n",
    "    'chart' : 0.1,\n",
    "    'chartered' : 0.1,\n",
    "    'chasing' : -0.2,\n",
    "    'cheap' : -0.8,\n",
    "    'check' : 0.2,\n",
    "    'civil' : 0.5,\n",
    "    'civilized' : 0.7,\n",
    "    'clues' : 0.1,\n",
    "    'compassionate' : 0.5,\n",
    "    'congratulations' : 1.5,\n",
    "    'contributor' : 0.2,\n",
    "    'contributors' : 0.2,\n",
    "    'cool' : 0.9,\n",
    "    'critical' : -0.6,\n",
    "    'damages' : -2.4,\n",
    "    'damn' : -1.4,\n",
    "    'death' : -2.7,\n",
    "    'declines' : -1.7,\n",
    "    'delay' : -1.0,\n",
    "    'delayed' : -1.0,\n",
    "    'disrupted' : -1.3,\n",
    "    'divisive' : -1.1,\n",
    "    'dropped' : -1.0,\n",
    "    'dumber' : -0.7,\n",
    "    'earnings' : 0.8,\n",
    "    'educated' : 1.2,\n",
    "    'education' : 1.3,\n",
    "    'emerging' : 1.4,\n",
    "    'empire' : 0.5,\n",
    "    'endorsement' : 0.9,\n",
    "    'endorsements' : 0.9,\n",
    "    'energy' : 0.4,\n",
    "    'engineers' : 0.2,\n",
    "    'enhance' : 0.8,\n",
    "    'enjoy' : 1.4,\n",
    "    'enormous' : 0.2,\n",
    "    'entertainment' : 0.7,\n",
    "    'equality' : 1.2,\n",
    "    'experience' : 1.4,\n",
    "    'exponential' : 0.8,\n",
    "    'fakeout' : -1.5,\n",
    "    'false' : -1.2,\n",
    "    'fight' : -1.4,\n",
    "    'fine' : 0.4,\n",
    "    'fit' : 0.2,\n",
    "    'foul' : -1.6,\n",
    "    'friend' : 0.6,\n",
    "    'friggin' : -1.2,\n",
    "    'fundamentals' : 0.3,\n",
    "    'future' : 0.4,\n",
    "    'gains' : 2.1,\n",
    "    'gold' : 1.3,\n",
    "    'good' : 1.0,\n",
    "    'green' : 1.7,\n",
    "    'growth' : 2.4,\n",
    "    'guarantee' : 0.7,\n",
    "    'hack' : -0.8,\n",
    "    'halt' : -1.4,\n",
    "    'halted' : -1.5,\n",
    "    'happy' : 1.2,\n",
    "    'hate' : -2.7,\n",
    "    'held' : 0.4,\n",
    "    'higher' : 1.2,\n",
    "    'hold' : 1.8,\n",
    "    'huge' : 0.2,\n",
    "    'ideas' : 0.1,\n",
    "    'impossible' : -1.4,\n",
    "    'incessantly' : -0.4,\n",
    "    'inflow' : 0.2,\n",
    "    'informed' : 0.5,\n",
    "    'insider' : 0.3,\n",
    "    'inverse' : -0.4,\n",
    "    'invest' : 1.5,\n",
    "    'investing' : 1.5,\n",
    "    'investor' : 0.2,\n",
    "    'investors' : 0.2,\n",
    "    'justice' : 1.4,\n",
    "    'leading' : 1.2,\n",
    "    'long' : 0.2,\n",
    "    'long-term' : 0.2,\n",
    "    'low' : -0.6,\n",
    "    'lower' : -0.6,\n",
    "    'major' : 0.4,\n",
    "    'mandatory' : -0.5,\n",
    "    'mayhem' : -1.4,\n",
    "    'official' : 0.2,\n",
    "    'officially' : 0.2,\n",
    "    'optimization' : 1.3,\n",
    "    'opportunity' : 2.0,\n",
    "    'passionate' : 1.3,\n",
    "    'pattern' : 0.1,\n",
    "    'peace' : 1.2,\n",
    "    'perfect' : 2.3,\n",
    "    'pragmatic' : -0.3,\n",
    "    'pretty' : 0.4,\n",
    "    'profits' : 1.2,\n",
    "    'protected' : 0.7,\n",
    "    'protection' : 0.6,\n",
    "    'proud' : 0.4,\n",
    "    'reliable' : 1.7,\n",
    "    'retirement' : 0.6,\n",
    "    'revolution' : 1.5,\n",
    "    'reward' : 2.0,\n",
    "    'rich' : 1.5,\n",
    "    'safety' : 1.4,\n",
    "    'scheme' : -2.3,\n",
    "    'science' : 0.2,\n",
    "    'scientific' : 0.2,\n",
    "    'shorting' : -0.4,\n",
    "    'squeeze' : 0.9,\n",
    "    'stern' : -0.4,\n",
    "    'sticky' : -0.2,\n",
    "    'stop' : -0.7,\n",
    "    'strip' : -0.3,\n",
    "    'strong' : 0.4,\n",
    "    'support' : 1.2,\n",
    "    'supporting' : 1.2,\n",
    "    'sustainable' : 1.6,\n",
    "    'swing' : -0.2,\n",
    "    'talent' : 0.5,\n",
    "    'tears' : -1.4,\n",
    "    'tension' : -1.7,\n",
    "    'unbiased' : 1.2,\n",
    "    'united' : 0.3,\n",
    "    'verified' : 0.1,\n",
    "    'volatility' : -1.3,\n",
    "    'warning' : -1.6,\n",
    "    'wellness' : 0.4,\n",
    "    'winning' : 1.2,\n",
    "    'worst' : -1.4,\n",
    "    'accept' : 1.2,\n",
    "    'aspiring' : 2.0,\n",
    "    'millionaire' : 1.0,\n",
    "    'billionaire' : 1.0,\n",
    "    'profit' : 2.3,\n",
    "    'corrupted' : -2.5,\n",
    "    'corrupt' : -2.4,\n",
    "    'enthusiast' : 0.4,\n",
    "    'takeover' : -1.6,\n",
    "    'withheld' : -1.4,\n",
    "}\n",
    "\n",
    "SIA.lexicon.update(Financial_Lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b529169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WriteBigTweetsCSV(Token, sinceID):\n",
    "    api = twitter.Api(consumer_key='eYvkuaFq8HkYXKvywv5LeMcVs',\n",
    "                  consumer_secret='jF0w2WeurHD4q17NSMfXXs4Wjovy969YgCFHDVB8fph9jzlQ85',\n",
    "                  access_token_key='721097810150612993-fCUeTJOsSK8qGxSHSwrUxg6PlHKCEZa',\n",
    "                  access_token_secret='qLGV8kCMFTJ5jrpUZGtjFFZ3xXxYjQxJmak2Jin6QlpDg',\n",
    "                  tweet_mode='extended')\n",
    "    results = api.GetSearch(term=Token, since_id=sinceID, count = 100, return_json='True')\n",
    "    with open('dump.json', 'w') as file:\n",
    "        file.write(json.dumps(results, indent=4))\n",
    "    data = json.load(open('dump.json'))\n",
    "    df = pd.json_normalize(data, record_path=['statuses'])\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    df = df[[\"user.followers_count\",\"user.friends_count\", \"user.listed_count\", \"user.favourites_count\", \"user.verified\",\"created_at\",\"full_text\",\"id\"]]\n",
    "    df = df[df['user.followers_count'] > 250]\n",
    "    final = df.sort_values('user.followers_count',ascending=False)\n",
    "    vslist = []\n",
    "    for sentence in final['full_text']:\n",
    "        vslist.append(SIA.polarity_scores(sentence).get(\"compound\"))\n",
    "    final['sentiment'] = vslist \n",
    "    #pd.DataFrame(columns=['index','user.followers_count','user.friends_count', 'user.listed_count', 'user.favourites_count', 'user.verified','created_at','full_text','id','sentiment']).to_csv(Token+'Tweets.csv', index=False)\n",
    "    #final.to_csv(Token+'Tweets.csv', header=None, index=False, mode='a')\n",
    "    final.to_csv('Desktop/Tinv-main/GUI/files/'+Token+'Tweets.csv', mode='a', header=['user.followers_count','user.friends_count', 'user.listed_count', 'user.favourites_count', 'user.verified','created_at','full_text','id','sentiment'])\n",
    "    result = pd.read_csv('Desktop/Tinv-main/GUI/files/'+Token+'Tweets.csv')\n",
    "    result = result[[\"created_at\",\"full_text\",\"sentiment\"]]\n",
    "    result = result.to_html()\n",
    "    with open(\"Desktop/Tinv-main/GUI/charts.html\", \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(result)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ff58630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WriteBigTweets(\"AMC\",1401654155157065730) #latest id should go here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd887e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WriteStockCSV(Name):\n",
    "    data = yf.download(Name, period=\"1d\", interval=\"1m\")\n",
    "    df = pd.DataFrame(data, columns = ['Open','High','Low','Close','Adj Close','Volume'])\n",
    "    df.to_csv(Name+'.csv')\n",
    "    df = pd.read_csv(Name+'.csv')\n",
    "    df['Dates'] = pd.to_datetime(df['Datetime'], format='%Y-%m-%d %H:%M').dt.date\n",
    "    df['Hour'] = pd.to_datetime(df['Datetime'], format='%Y-%m-%d %H:%M').dt.time\n",
    "    df.drop(df.columns[[0]], axis = 1, inplace = True)\n",
    "    #Uncomment for stock market after hours, where we'd potentially get data from different days\n",
    "    #df_list = [d for _, d in df.groupby(['Dates'])]\n",
    "    #temp = df_list[0]\n",
    "    df.to_csv('Desktop/Tinv-main/GUI/files/'+Name+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f66589d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PredictStock(Name):\n",
    "    df = pd.read_csv('Desktop/Tinv-main/GUI/files/'+Name+'.csv')\n",
    "    predictionlength = min(len(df.index)//2, 25)\n",
    "    Predictions = loadedmodel.predict(start=df.last_valid_index(), end=df.last_valid_index()+predictionlength)\n",
    "    Predictions = Predictions*(df.iloc[-1]['Close']/Predictions.iloc[0])\n",
    "    #create hours\n",
    "    df['Hour'] = pd.to_datetime(df['Hour'], format='%H:%M:%S').dt.time\n",
    "    oneminute = datetime.timedelta(minutes=1)\n",
    "    temp = time_plus(df['Hour'].iloc[-1],oneminute)\n",
    "    hourlist = []\n",
    "    for row in Predictions:\n",
    "        hourlist.append(temp)\n",
    "        temp = time_plus(temp,oneminute)\n",
    "    Predictions = Predictions.to_frame(name='Close')\n",
    "    Predictions['Hour'] = hourlist\n",
    "    Predictions.to_csv('Desktop/Tinv-main/GUI/files/'+Name+'prediction.csv')\n",
    "    \n",
    "    \n",
    "def time_plus(time, timedelta):\n",
    "    start = datetime.datetime(\n",
    "        2000, 1, 1,\n",
    "        hour=time.hour, minute=time.minute, second=time.second)\n",
    "    end = start + timedelta\n",
    "    return end.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "713cc349",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLatestID(Name):\n",
    "    #try:\n",
    "        df = pd.read_csv('Desktop/Tinv-main/GUI/files/'+Name+'Tweets.csv', header=0)\n",
    "        max = 0\n",
    "        for id in df['id']:\n",
    "            if(id!=\"id\"):\n",
    "                if (int(id)>max):\n",
    "                    max = int(id)\n",
    "        return max\n",
    "    #except:\n",
    "        #return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf09b8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['user.followers_count', 'user.friends_count', 'user.listed_count',\\n       'user.favourites_count', 'user.verified', 'created_at', 'full_text',\\n       'id'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-70c7700e939b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mWriteStockCSV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"NVDA\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mWriteBigTweetsCSV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"NVDA\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgetLatestID\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"NVDA\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#we need to find a way to get latest id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mPredictStock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"NVDA\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-02030c61337b>\u001b[0m in \u001b[0;36mWriteBigTweetsCSV\u001b[1;34m(Token, sinceID)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson_normalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'statuses'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'display.max_columns'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"user.followers_count\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"user.friends_count\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"user.listed_count\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"user.favourites_count\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"user.verified\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"created_at\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"full_text\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user.followers_count'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m250\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mfinal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'user.followers_count'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-test\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3028\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3030\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3032\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-test\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf-test\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1307\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1308\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1310\u001b[0m             \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['user.followers_count', 'user.friends_count', 'user.listed_count',\\n       'user.favourites_count', 'user.verified', 'created_at', 'full_text',\\n       'id'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "WriteStockCSV(\"AMC\")\n",
    "WriteBigTweetsCSV(\"AMC\",0) #we need to find a way to get latest id\n",
    "PredictStock(\"AMC\")\n",
    "time.sleep(15)\n",
    "WriteStockCSV(\"GME\")\n",
    "WriteBigTweetsCSV(\"GME\",0) #we need to find a way to get latest id\n",
    "PredictStock(\"GME\")\n",
    "time.sleep(15)\n",
    "WriteStockCSV(\"AMZN\")\n",
    "WriteBigTweetsCSV(\"AMZN\",0) #we need to find a way to get latest id\n",
    "PredictStock(\"AMZN\")\n",
    "time.sleep(15)\n",
    "WriteStockCSV(\"NVDA\")\n",
    "WriteBigTweetsCSV(\"NVDA\",0) #we need to find a way to get latest id\n",
    "PredictStock(\"NVDA\")\n",
    "while True:\n",
    "    WriteStockCSV(\"AMC\")\n",
    "    WriteBigTweetsCSV(\"AMC\",getLatestID(\"AMC\")) #we need to find a way to get latest id\n",
    "    PredictStock(\"AMC\")\n",
    "    time.sleep(15)\n",
    "    WriteStockCSV(\"GME\")\n",
    "    WriteBigTweetsCSV(\"GME\",getLatestID(\"GME\")) #we need to find a way to get latest id\n",
    "    PredictStock(\"GME\")\n",
    "    time.sleep(15)\n",
    "    WriteStockCSV(\"AMZN\")\n",
    "    WriteBigTweetsCSV(\"AMZN\",getLatestID(\"AMZN\")) #we need to find a way to get latest id\n",
    "    PredictStock(\"AMZN\")\n",
    "    time.sleep(15)\n",
    "    WriteStockCSV(\"NVDA\")\n",
    "    WriteBigTweetsCSV(\"NVDA\",getLatestID(\"NVDA\")) #we need to find a way to get latest id\n",
    "    PredictStock(\"NVDA\")\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a2eccb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "WriteBigTweetsCSV(\"NVDA\",0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccba7ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
